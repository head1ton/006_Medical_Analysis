{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOHP4/AemkigepIunxoJ9uI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/head1ton/006_Medical_Analysis/blob/main/notebook/Brain_MRI_NIfTI_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWZWVf4grZXz"
      },
      "outputs": [],
      "source": [
        "# 필요한 라이브러리 설치\n",
        "!pip install nibabel matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 샘플 NIfTI 생성 코드\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "GGIycMd4rnyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 경로 설정\n",
        "output_dir = Path(\"nifti_sample\")\n",
        "output_dir.mkdir(exist_ok=True)"
      ],
      "metadata": {
        "id": "myjSEtU8rrCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 샘플 데이터 생성\n",
        "def generate_sample_nifti(shape=(64, 64, 32), mask_ratio=0.2):\n",
        "    img_data = np.random.rand(*shape).astype(np.float32)\n",
        "    mask_data = (np.random.rand(*shape) < mask_ratio).astype(np.uint8)\n",
        "\n",
        "    affine = np.eye(4)\n",
        "    img_nii = nib.Nifti1Image(img_data, affine)\n",
        "    mask_nii = nib.Nifti1Image(mask_data, affine)\n",
        "    return img_nii, mask_nii"
      ],
      "metadata": {
        "id": "ECb4d7XBrq_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일 생성 및 저장\n",
        "img_nii, mask_nii = generate_sample_nifti()\n",
        "nib.save(img_nii, str(output_dir / \"sample_brain.nii.gz\"))\n",
        "nib.save(mask_nii, str(output_dir / \"sample_mask.nii.gz\"))"
      ],
      "metadata": {
        "id": "WXJ7l2o2rq8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 중간 slice 시각화\n",
        "middle_slice = img_nii.get_fdata()[:, :, img_nii.shape[-1] // 2]\n",
        "plt.imshow(middle_slice, cmap=\"gray\")\n",
        "plt.title(\"🧠 Sample Brain MRI (Middle Slice)\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SPx_yQjOrq6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x3Jw2y4_rq3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## nifti_loader\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "class BrainMRIDataset(Dataset):\n",
        "    def __init__(self, img_path, mask_path, transform=None):\n",
        "        self.img_nii = nib.load(img_path).get_fdata()\n",
        "        self.mask_nii = nib.load(mask_path).get_fdata()\n",
        "        self.transform = transform\n",
        "\n",
        "        assert self.img_nii.shape == self.mask_nii.shape, \"이미지와 마스크 shape이 다릅니다.\"\n",
        "        self.slices = self.img_nii.shape[2]  # z축 기준 슬라이스 수\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.slices\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_slice = self.img_nii[:, :, idx]\n",
        "        mask_slice = self.mask_nii[:, :, idx]\n",
        "\n",
        "        # 정규화\n",
        "        img_slice = (img_slice - np.min(img_slice)) / (np.max(img_slice) - np.min(img_slice) + 1e-5)\n",
        "\n",
        "        # 차원 확장 (1, H, W)\n",
        "        img = torch.tensor(img_slice, dtype=torch.float32).unsqueeze(0)\n",
        "        mask = torch.tensor(mask_slice, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "            mask = self.transform(mask)\n",
        "\n",
        "        return img, mask\n"
      ],
      "metadata": {
        "id": "g1aCX2ymrq1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 경로 설정\n",
        "img_path = \"nifti_sample/sample_brain.nii.gz\"\n",
        "mask_path = \"nifti_sample/sample_mask.nii.gz\"\n",
        "\n",
        "# 데이터셋 정의\n",
        "dataset = BrainMRIDataset(img_path, mask_path)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# DataLoader 구성\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)"
      ],
      "metadata": {
        "id": "yqEH3khCrqyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## UNet++ (Nested UNet)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class UNetPlusPlus(nn.Module):\n",
        "    def __init__(self, in_ch=1, out_ch=1, filters=[32, 64, 128, 256, 512]):\n",
        "        super(UNetPlusPlus, self).__init__()\n",
        "        self.conv0_0 = ConvBlock(in_ch, filters[0])\n",
        "        self.conv1_0 = ConvBlock(filters[0], filters[1])\n",
        "        self.conv2_0 = ConvBlock(filters[1], filters[2])\n",
        "        self.conv3_0 = ConvBlock(filters[2], filters[3])\n",
        "        self.conv4_0 = ConvBlock(filters[3], filters[4])\n",
        "\n",
        "        self.up1_0 = nn.ConvTranspose2d(filters[1], filters[0], 2, stride=2)\n",
        "        self.up2_0 = nn.ConvTranspose2d(filters[2], filters[1], 2, stride=2)\n",
        "        self.up3_0 = nn.ConvTranspose2d(filters[3], filters[2], 2, stride=2)\n",
        "        self.up4_0 = nn.ConvTranspose2d(filters[4], filters[3], 2, stride=2)\n",
        "\n",
        "        self.conv0_1 = ConvBlock(filters[0]+filters[0], filters[0])\n",
        "        self.conv1_1 = ConvBlock(filters[1]+filters[1], filters[1])\n",
        "        self.conv2_1 = ConvBlock(filters[2]+filters[2], filters[2])\n",
        "        self.conv3_1 = ConvBlock(filters[3]+filters[3], filters[3])\n",
        "\n",
        "        self.up1_1 = nn.ConvTranspose2d(filters[1], filters[0], 2, stride=2)\n",
        "        self.up2_1 = nn.ConvTranspose2d(filters[2], filters[1], 2, stride=2)\n",
        "        self.up3_1 = nn.ConvTranspose2d(filters[3], filters[2], 2, stride=2)\n",
        "\n",
        "        self.conv0_2 = ConvBlock(filters[0]*3, filters[0])\n",
        "        self.final = nn.Conv2d(filters[0], out_ch, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x0_0 = self.conv0_0(x)\n",
        "        x1_0 = self.conv1_0(F.max_pool2d(x0_0, 2))\n",
        "        x0_1 = self.conv0_1(torch.cat([x0_0, self.up1_0(x1_0)], 1))\n",
        "\n",
        "        x2_0 = self.conv2_0(F.max_pool2d(x1_0, 2))\n",
        "        x1_1 = self.conv1_1(torch.cat([x1_0, self.up2_0(x2_0)], 1))\n",
        "        x0_2 = self.conv0_2(torch.cat([x0_0, x0_1, self.up1_1(x1_1)], 1))\n",
        "\n",
        "        x3_0 = self.conv3_0(F.max_pool2d(x2_0, 2))\n",
        "        x2_1 = self.conv2_1(torch.cat([x2_0, self.up3_0(x3_0)], 1))\n",
        "\n",
        "        out = self.final(x0_2)\n",
        "        return torch.sigmoid(out)\n"
      ],
      "metadata": {
        "id": "TALd08FKrqvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = UNetPlusPlus(in_ch=1, out_ch=1)\n",
        "x = torch.randn(1, 1, 64, 64)  # batch, channel, H, W\n",
        "y = model(x)\n",
        "print(\"Output shape:\", y.shape)"
      ],
      "metadata": {
        "id": "89yzxpvVrqtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5yoRHeJ8rqqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## loss_metric\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, smooth=1.):\n",
        "        super(DiceLoss, self).__init__()\n",
        "        self.smooth = smooth\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        pred = pred.contiguous()\n",
        "        target = target.contiguous()\n",
        "\n",
        "        intersection = (pred * target).sum(dim=(2,3))\n",
        "        dice = (2. * intersection + self.smooth) / (pred.sum(dim=(2,3)) + target.sum(dim=(2,3)) + self.smooth)\n",
        "        return 1 - dice.mean()\n",
        "\n",
        "def dice_score(pred, target, threshold=0.5):\n",
        "    pred = (pred > threshold).float()\n",
        "    intersection = (pred * target).sum()\n",
        "    union = pred.sum() + target.sum()\n",
        "    return (2. * intersection / (union + 1e-5)).item()"
      ],
      "metadata": {
        "id": "bzXjEAkKrqny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## train\n",
        "import torch\n",
        "from loss_metric import DiceLoss, dice_score\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "def train_model(model, train_loader, val_loader, device, epochs=20, lr=1e-3, save_path=\"unetpp_model.pt\"):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = DiceLoss()\n",
        "    bce = torch.nn.BCELoss()\n",
        "\n",
        "    model.to(device)\n",
        "    best_val_dice = 0.0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for img, mask in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\"):\n",
        "            img, mask = img.to(device), mask.to(device)\n",
        "\n",
        "            pred = model(img)\n",
        "            loss = criterion(pred, mask) + bce(pred, mask)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        model.eval()\n",
        "        val_dice = 0\n",
        "        with torch.no_grad():\n",
        "            for img, mask in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} [Val]\"):\n",
        "                img, mask = img.to(device), mask.to(device)\n",
        "                pred = model(img)\n",
        "                val_dice += dice_score(pred, mask)\n",
        "\n",
        "        avg_val_dice = val_dice / len(val_loader)\n",
        "        print(f\"[Epoch {epoch+1}] Train Loss: {train_loss/len(train_loader):.4f} | Val Dice: {avg_val_dice:.4f}\")\n",
        "\n",
        "        if avg_val_dice > best_val_dice:\n",
        "            best_val_dice = avg_val_dice\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            print(f\"✅ Best model saved to {save_path}\")\n",
        "\n",
        "def load_model(model, path, device):\n",
        "    model.load_state_dict(torch.load(path, map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "8XGPRJROrqlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from unetpp import UNetPlusPlus\n",
        "from train import train_model\n",
        "from nifti_loader import BrainMRIDataset\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = UNetPlusPlus(in_ch=1, out_ch=1)\n",
        "\n",
        "dataset = BrainMRIDataset(\"nifti_sample/sample_brain.nii.gz\", \"nifti_sample/sample_mask.nii.gz\")\n",
        "train_ds, val_ds = random_split(dataset, [int(0.8 * len(dataset)), len(dataset) - int(0.8 * len(dataset))])\n",
        "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=4, shuffle=False)\n",
        "\n",
        "train_model(model, train_loader, val_loader, device, epochs=10, save_path=\"unetpp_brain_mri.pt\")\n"
      ],
      "metadata": {
        "id": "zsfnfCUOrqil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LSQRV267rqfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 예측 + 시각화 (NIfTI + UNet++)\n",
        "import nibabel as nib\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "from unetpp import UNetPlusPlus\n",
        "from train import load_model\n",
        "\n",
        "def normalize(img):\n",
        "    img = (img - np.min(img)) / (np.max(img) - np.min(img) + 1e-5)\n",
        "    return img\n",
        "\n",
        "def visualize_prediction(model_path, image_path, mask_path=None, slice_idx=80):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Load image\n",
        "    img_nii = nib.load(image_path)\n",
        "    img_data = img_nii.get_fdata()\n",
        "    img = img_data[:, :, slice_idx]\n",
        "    img = normalize(img)\n",
        "\n",
        "    # Prepare input\n",
        "    input_tensor = torch.tensor(img, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
        "\n",
        "    # Load model\n",
        "    model = UNetPlusPlus(in_ch=1, out_ch=1)\n",
        "    model = load_model(model, model_path, device)\n",
        "\n",
        "    # Predict\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)\n",
        "        pred = output.squeeze().cpu().numpy()\n",
        "        pred_mask = (pred > 0.5).astype(np.uint8)\n",
        "\n",
        "    # Optional: Load GT mask\n",
        "    gt_mask = None\n",
        "    if mask_path:\n",
        "        mask_nii = nib.load(mask_path)\n",
        "        gt_data = mask_nii.get_fdata()\n",
        "        gt_mask = gt_data[:, :, slice_idx]\n",
        "\n",
        "    # Visualization\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.title(\"Original MRI\")\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    if gt_mask is not None:\n",
        "        plt.imshow(img, cmap='gray')\n",
        "        plt.imshow(gt_mask, alpha=0.4, cmap='Reds')\n",
        "        plt.title(\"Ground Truth Mask\")\n",
        "    else:\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    overlay = cv2.addWeighted((img * 255).astype(np.uint8), 1.0, (pred_mask * 255).astype(np.uint8), 0.5, 0)\n",
        "    plt.imshow(overlay, cmap='gray')\n",
        "    plt.title(\"Predicted Mask\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "po6YrCSyrqcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_prediction(\n",
        "    model_path=\"unetpp_brain_mri.pt\",\n",
        "    image_path=\"nifti_sample/sample_brain.nii.gz\",\n",
        "    mask_path=\"nifti_sample/sample_mask.nii.gz\",  # 생략 가능\n",
        "    slice_idx=80\n",
        ")"
      ],
      "metadata": {
        "id": "B5I5GcQ-tNu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RmiGnYectNsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## streamlit (streamlit run streamlit_app.py)\n",
        "import streamlit as st\n",
        "import nibabel as nib\n",
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tempfile\n",
        "import matplotlib.pyplot as plt\n",
        "from unetpp import UNetPlusPlus\n",
        "from train import load_model\n",
        "\n",
        "st.set_page_config(layout=\"wide\", page_title=\"Brain MRI Segmentation Demo\")\n",
        "\n",
        "def normalize(img):\n",
        "    img = (img - np.min(img)) / (np.max(img) - np.min(img) + 1e-5)\n",
        "    return img\n",
        "\n",
        "def load_nifti(file):\n",
        "    nii = nib.load(file)\n",
        "    return nii.get_fdata()\n",
        "\n",
        "def predict_slice(model, image_slice, device):\n",
        "    img = normalize(image_slice)\n",
        "    tensor = torch.tensor(img, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        pred = model(tensor)\n",
        "        pred = (pred.squeeze().cpu().numpy() > 0.5).astype(np.uint8)\n",
        "    return pred\n",
        "\n",
        "def show_overlay(image, pred_mask, title=\"Prediction Overlay\"):\n",
        "    overlay = cv2.addWeighted((image*255).astype(np.uint8), 1.0, (pred_mask*255).astype(np.uint8), 0.5, 0)\n",
        "    st.image(overlay, caption=title, use_column_width=True, channels=\"GRAY\")\n",
        "\n",
        "# Sidebar\n",
        "st.sidebar.title(\"Upload Files\")\n",
        "image_file = st.sidebar.file_uploader(\"Upload Brain MRI (.nii.gz)\", type=[\"nii\", \"nii.gz\"])\n",
        "mask_file = st.sidebar.file_uploader(\"Upload Ground Truth Mask (Optional)\", type=[\"nii\", \"nii.gz\"])\n",
        "model_file = st.sidebar.file_uploader(\"Upload Trained Model (.pt)\", type=[\"pt\"])\n",
        "slice_idx = st.sidebar.slider(\"Slice Index\", 0, 200, 80)\n",
        "\n",
        "# Main\n",
        "st.title(\"🧠 Brain MRI Segmentation with UNet++\")\n",
        "\n",
        "if image_file and model_file:\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Save temp files\n",
        "    with tempfile.NamedTemporaryFile(delete=False) as tmp_img:\n",
        "        tmp_img.write(image_file.read())\n",
        "        image_path = tmp_img.name\n",
        "\n",
        "    with tempfile.NamedTemporaryFile(delete=False) as tmp_model:\n",
        "        tmp_model.write(model_file.read())\n",
        "        model_path = tmp_model.name\n",
        "\n",
        "    # Load data\n",
        "    img_data = load_nifti(image_path)\n",
        "    img_slice = img_data[:, :, slice_idx]\n",
        "    norm_img = normalize(img_slice)\n",
        "\n",
        "    # Load model\n",
        "    model = UNetPlusPlus(in_ch=1, out_ch=1)\n",
        "    model = load_model(model, model_path, device)\n",
        "\n",
        "    # Predict\n",
        "    pred_mask = predict_slice(model, img_slice, device)\n",
        "\n",
        "    # Display\n",
        "    col1, col2, col3 = st.columns(3)\n",
        "\n",
        "    with col1:\n",
        "        st.image(norm_img, caption=\"Original MRI\", use_column_width=True, channels=\"GRAY\")\n",
        "    with col2:\n",
        "        if mask_file:\n",
        "            with tempfile.NamedTemporaryFile(delete=False) as tmp_mask:\n",
        "                tmp_mask.write(mask_file.read())\n",
        "                mask_path = tmp_mask.name\n",
        "            gt_mask = load_nifti(mask_path)[:, :, slice_idx]\n",
        "            st.image(gt_mask, caption=\"Ground Truth Mask\", use_column_width=True)\n",
        "        else:\n",
        "            st.info(\"No ground truth uploaded.\")\n",
        "    with col3:\n",
        "        show_overlay(norm_img, pred_mask)\n",
        "\n",
        "else:\n",
        "    st.info(\"Please upload both MRI and model files.\")"
      ],
      "metadata": {
        "id": "vT3NNjuqtNmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w1btiV9PtNkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### IR 논문 포멧 자동 리포트(LaTeX 포함)\n",
        "# ir_report_generator.py (실행- python ir_report_generator.py)\n",
        "\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "TEMPLATE = r\"\"\"\n",
        "\\documentclass{article}\n",
        "\\usepackage{graphicx}\n",
        "\\usepackage{geometry}\n",
        "\\geometry{margin=1in}\n",
        "\\title{{\\bfseries Brain MRI Segmentation Report}}\n",
        "\\author{{AI Medical Lab}}\n",
        "\\date{{\\today}}\n",
        "\n",
        "\\begin{document}\n",
        "\n",
        "\\maketitle\n",
        "\n",
        "\\section*{1. Introduction}\n",
        "This report summarizes the deep learning-based brain MRI segmentation task using UNet++ architecture.\n",
        "\n",
        "\\section*{2. Dataset}\n",
        "The dataset used for training and evaluation consists of NIfTI-format brain MRI scans with corresponding ground truth segmentation masks. Preprocessing involved slice extraction and normalization.\n",
        "\n",
        "\\section*{3. Model Architecture}\n",
        "The model employed is UNet++, a nested U-Net architecture known for improved segmentation performance in biomedical imaging.\n",
        "\n",
        "\\section*{4. Training Setup}\n",
        "\n",
        "\\begin{itemize}\n",
        "  \\item Epochs: {epochs}\n",
        "  \\item Batch Size: {batch_size}\n",
        "  \\item Optimizer: Adam\n",
        "  \\item Learning Rate: {learning_rate}\n",
        "  \\item Loss Function: BCE + Dice Loss\n",
        "\\end{itemize}\n",
        "\n",
        "\\section*{5. Evaluation Results}\n",
        "\n",
        "\\begin{itemize}\n",
        "  \\item Dice Score: {dice_score:.4f}\n",
        "  \\item IoU Score: {iou_score:.4f}\n",
        "\\end{itemize}\n",
        "\n",
        "\\section*{6. Visual Results}\n",
        "\\begin{figure}[h!]\n",
        "\\centering\n",
        "\\includegraphics[width=0.6\\textwidth]{{{image_path}}}\n",
        "\\caption{Prediction result for slice {slice_idx} with mask overlay.}\n",
        "\\end{figure}\n",
        "\n",
        "\\end{document}\n",
        "\"\"\"\n",
        "\n",
        "def generate_latex_report(save_path, metrics, image_path, hyperparams):\n",
        "    tex_code = TEMPLATE.format(\n",
        "        dice_score=metrics['dice'],\n",
        "        iou_score=metrics['iou'],\n",
        "        image_path=image_path,\n",
        "        slice_idx=hyperparams['slice_idx'],\n",
        "        epochs=hyperparams['epochs'],\n",
        "        batch_size=hyperparams['batch_size'],\n",
        "        learning_rate=hyperparams['learning_rate']\n",
        "    )\n",
        "\n",
        "    tex_file = os.path.join(save_path, \"segmentation_report.tex\")\n",
        "    with open(tex_file, \"w\") as f:\n",
        "        f.write(tex_code)\n",
        "    print(f\"LaTeX report generated at {tex_file}\")\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    metrics = {'dice': 0.8721, 'iou': 0.7943}\n",
        "    image_path = \"overlay_result.png\"\n",
        "    hyperparams = {'slice_idx': 80, 'epochs': 50, 'batch_size': 8, 'learning_rate': 0.0001}\n",
        "    generate_latex_report(\"./\", metrics, image_path, hyperparams)\n"
      ],
      "metadata": {
        "id": "dT0A1y1JtNhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## JSRT / Montgomery 데이터 기반 흉부 X-ray (DICOM) 확장\n",
        "\n",
        "# dicom_xray_pipeline.py\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import pydicom\n",
        "import numpy as np\n",
        "import cv2\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class DICOMXrayDataset(Dataset):\n",
        "    def __init__(self, dicom_dir, mask_dir=None, transform=None):\n",
        "        self.dicom_paths = sorted(glob.glob(os.path.join(dicom_dir, \"*.dcm\")))\n",
        "        self.mask_paths = sorted(glob.glob(os.path.join(mask_dir, \"*.png\"))) if mask_dir else None\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dicom_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        dicom_path = self.dicom_paths[idx]\n",
        "        ds = pydicom.dcmread(dicom_path)\n",
        "        img = ds.pixel_array.astype(np.float32)\n",
        "        img = (img - np.min(img)) / (np.max(img) - np.min(img) + 1e-5)\n",
        "        img = np.expand_dims(img, axis=0)\n",
        "\n",
        "        sample = {\"image\": img}\n",
        "\n",
        "        if self.mask_paths:\n",
        "            mask_path = self.mask_paths[idx]\n",
        "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "            mask = (mask > 127).astype(np.float32)\n",
        "            mask = np.expand_dims(mask, axis=0)\n",
        "            sample[\"mask\"] = mask\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample\n",
        "\n",
        "# --- Example usage ---\n",
        "if __name__ == \"__main__\":\n",
        "    dataset = DICOMXrayDataset(dicom_dir=\"/montgomery/images\", mask_dir=\"/masks\")\n",
        "    print(\"Sample shape:\", dataset[0]['image'].shape)\n"
      ],
      "metadata": {
        "id": "NQKxReUktNfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kw4Q9zA2tNc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 뇌 MRI 세그멘테이션을 위한 NIfTI (.nii.gz) 버전\n",
        "\n",
        "# dicom_xray_pipeline.py\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import pydicom\n",
        "import numpy as np\n",
        "import cv2\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class DICOMXrayDataset(Dataset):\n",
        "    def __init__(self, dicom_dir, mask_dir=None, transform=None):\n",
        "        self.dicom_paths = sorted(glob.glob(os.path.join(dicom_dir, \"*.dcm\")))\n",
        "        self.mask_paths = sorted(glob.glob(os.path.join(mask_dir, \"*.png\"))) if mask_dir else None\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dicom_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        dicom_path = self.dicom_paths[idx]\n",
        "        ds = pydicom.dcmread(dicom_path)\n",
        "        img = ds.pixel_array.astype(np.float32)\n",
        "        img = (img - np.min(img)) / (np.max(img) - np.min(img) + 1e-5)\n",
        "        img = np.expand_dims(img, axis=0)\n",
        "\n",
        "        sample = {\"image\": img}\n",
        "\n",
        "        if self.mask_paths:\n",
        "            mask_path = self.mask_paths[idx]\n",
        "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "            mask = (mask > 127).astype(np.float32)\n",
        "            mask = np.expand_dims(mask, axis=0)\n",
        "            sample[\"mask\"] = mask\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample\n",
        "\n",
        "# --- Example usage ---\n",
        "if __name__ == \"__main__\":\n",
        "    dataset = DICOMXrayDataset(dicom_dir=\"/montgomery/images\", mask_dir=\"/masks\")\n",
        "    print(\"Sample shape:\", dataset[0]['image'].shape)\n"
      ],
      "metadata": {
        "id": "RXwFMZgitNZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J0Y-c63rtNXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Nifti Brain Dataset\n",
        "\n",
        "# nifti_brain_dataset.py\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class NiftiBrainMRIDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir=None, transform=None):\n",
        "        self.image_paths = sorted(glob.glob(os.path.join(image_dir, '*.nii*')))\n",
        "        self.mask_paths = sorted(glob.glob(os.path.join(mask_dir, '*.nii*'))) if mask_dir else None\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        img_nii = nib.load(img_path)\n",
        "        img = img_nii.get_fdata().astype(np.float32)\n",
        "\n",
        "        # Normalize image\n",
        "        img = (img - np.min(img)) / (np.max(img) - np.min(img) + 1e-5)\n",
        "\n",
        "        # Select middle slice for 2D segmentation (can be extended to 3D)\n",
        "        z = img.shape[2] // 2\n",
        "        img_slice = img[:, :, z]\n",
        "        img_slice = np.expand_dims(img_slice, axis=0)  # shape (1, H, W)\n",
        "\n",
        "        sample = {\"image\": img_slice}\n",
        "\n",
        "        if self.mask_paths:\n",
        "            mask_path = self.mask_paths[idx]\n",
        "            mask_nii = nib.load(mask_path)\n",
        "            mask = mask_nii.get_fdata()\n",
        "            mask_slice = (mask[:, :, z] > 0).astype(np.float32)\n",
        "            mask_slice = np.expand_dims(mask_slice, axis=0)  # shape (1, H, W)\n",
        "            sample[\"mask\"] = mask_slice\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample\n",
        "\n",
        "# Example\n",
        "if __name__ == '__main__':\n",
        "    dataset = NiftiBrainMRIDataset(\n",
        "        image_dir=\"/brain/images\",\n",
        "        mask_dir=\"/brain/masks\"\n",
        "    )\n",
        "    print(\"Sample shape:\", dataset[0]['image'].shape)\n"
      ],
      "metadata": {
        "id": "6UZy5hqYtNUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Be-WRRhHu1lu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VUEFY4ZCu1iY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## UNet++ 모델\n",
        "# app.py (Gradio HuggingFace Spaces + HF Model Hub 다운로드 지원)\n",
        "\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "import pydicom\n",
        "import nibabel as nib\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from unet_model import UNet\n",
        "from unetpp_model import UNetPP\n",
        "from PIL import Image\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "\n",
        "# Auto-download model weights from Hugging Face Hub\n",
        "def load_model_weights_local_or_hf(model, filename, repo_id, subfolder=None):\n",
        "    if os.path.exists(filename):\n",
        "        model.load_state_dict(torch.load(filename, map_location=\"cpu\"))\n",
        "    else:\n",
        "        print(f\"🔁 Downloading {filename} from HF Hub...\")\n",
        "        model_path = hf_hub_download(repo_id=repo_id, filename=os.path.basename(filename), subfolder=subfolder)\n",
        "        model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# Load models\n",
        "unet_model = UNet()\n",
        "unet_model = load_model_weights_local_or_hf(\n",
        "    unet_model,\n",
        "    filename=\"results/xray_unet_epoch30.pth\",\n",
        "    repo_id=\"your-hf-username/xray-unet\",\n",
        "    subfolder=\"models\"\n",
        ")\n",
        "\n",
        "unetpp_model = UNetPP()\n",
        "unetpp_model = load_model_weights_local_or_hf(\n",
        "    unetpp_model,\n",
        "    filename=\"results/unetpp_epoch25.pth\",\n",
        "    repo_id=\"your-hf-username/mri-unetpp\",\n",
        "    subfolder=\"models\"\n",
        ")\n",
        "\n",
        "\n",
        "# Utils\n",
        "def preprocess(img):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize((256, 256))\n",
        "    ])\n",
        "    return transform(img).unsqueeze(0)\n",
        "\n",
        "def overlay_prediction(img, mask):\n",
        "    img = (img * 255).astype(np.uint8)\n",
        "    img_rgb = np.stack([img]*3, axis=-1)\n",
        "    mask_bin = (mask > 0.5).astype(np.uint8)\n",
        "    mask_rgb = np.zeros_like(img_rgb)\n",
        "    mask_rgb[:, :, 1] = mask_bin * 255\n",
        "    overlaid = (0.7 * img_rgb + 0.3 * mask_rgb).astype(np.uint8)\n",
        "    return Image.fromarray(overlaid)\n",
        "\n",
        "\n",
        "def predict_dcm(file):\n",
        "    dcm = pydicom.dcmread(file.name)\n",
        "    img = dcm.pixel_array.astype(np.float32)\n",
        "    img = (img - np.min(img)) / (np.max(img) - np.min(img))\n",
        "    input_tensor = preprocess(img)\n",
        "    with torch.no_grad():\n",
        "        pred = torch.sigmoid(unet_model(input_tensor)).squeeze().numpy()\n",
        "    result = overlay_prediction(img, pred)\n",
        "    return result\n",
        "\n",
        "\n",
        "def predict_nii(file, slice_index):\n",
        "    nifti = nib.load(file.name)\n",
        "    data = nifti.get_fdata()\n",
        "    slice_img = data[:, :, slice_index]\n",
        "    norm_img = (slice_img - np.min(slice_img)) / (np.max(slice_img) - np.min(slice_img))\n",
        "    input_tensor = preprocess(norm_img)\n",
        "    with torch.no_grad():\n",
        "        pred = torch.sigmoid(unetpp_model(input_tensor)).squeeze().numpy()\n",
        "    result = overlay_prediction(norm_img, pred)\n",
        "    return result\n",
        "\n",
        "\n",
        "def xray_interface():\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"# 🩻 Chest X-ray Segmentation\")\n",
        "        file_input = gr.File(label=\"Upload DICOM (.dcm)\")\n",
        "        output_img = gr.Image(label=\"Overlayed Prediction\")\n",
        "        file_input.change(predict_dcm, inputs=file_input, outputs=output_img)\n",
        "    return demo\n",
        "\n",
        "\n",
        "def mri_interface():\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"# 🧠 Brain MRI Segmentation\")\n",
        "        file_input = gr.File(label=\"Upload NIfTI (.nii.gz)\")\n",
        "        slice_slider = gr.Slider(0, 150, step=1, label=\"Slice Index\", value=60)\n",
        "        output_img = gr.Image(label=\"Overlayed Prediction\")\n",
        "        gr.Button(\"Predict\").click(predict_nii, inputs=[file_input, slice_slider], outputs=output_img)\n",
        "    return demo\n",
        "\n",
        "\n",
        "def main():\n",
        "    with gr.TabbedInterface([xray_interface(), mri_interface()], [\"X-ray\", \"MRI\"]):\n",
        "        pass\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "Xf2hXwHeu1f5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BtOU69q7u1dm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "import pydicom\n",
        "import nibabel as nib\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from unet_model import UNet\n",
        "from unetpp_model import UNetPP\n",
        "from PIL import Image\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "\n",
        "# Auto-download model weights from Hugging Face Hub\n",
        "def load_model_weights_local_or_hf(model, filename, repo_id, subfolder=None):\n",
        "    if os.path.exists(filename):\n",
        "        model.load_state_dict(torch.load(filename, map_location=\"cpu\"))\n",
        "    else:\n",
        "        print(f\"🔁 Downloading {filename} from HF Hub...\")\n",
        "        model_path = hf_hub_download(repo_id=repo_id, filename=os.path.basename(filename), subfolder=subfolder)\n",
        "        model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# Load models\n",
        "unet_model = UNet()\n",
        "unet_model = load_model_weights_local_or_hf(\n",
        "    unet_model,\n",
        "    filename=\"results/xray_unet_epoch30.pth\",\n",
        "    repo_id=\"your-hf-username/xray-unet\",\n",
        "    subfolder=\"models\"\n",
        ")\n",
        "\n",
        "unetpp_model = UNetPP()\n",
        "unetpp_model = load_model_weights_local_or_hf(\n",
        "    unetpp_model,\n",
        "    filename=\"results/unetpp_epoch25.pth\",\n",
        "    repo_id=\"your-hf-username/mri-unetpp\",\n",
        "    subfolder=\"models\"\n",
        ")\n",
        "\n",
        "\n",
        "# Utils\n",
        "def preprocess(img):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize((256, 256))\n",
        "    ])\n",
        "    return transform(img).unsqueeze(0)\n",
        "\n",
        "def overlay_prediction(img, mask):\n",
        "    img = (img * 255).astype(np.uint8)\n",
        "    img_rgb = np.stack([img]*3, axis=-1)\n",
        "    mask_bin = (mask > 0.5).astype(np.uint8)\n",
        "    mask_rgb = np.zeros_like(img_rgb)\n",
        "    mask_rgb[:, :, 1] = mask_bin * 255\n",
        "    overlaid = (0.7 * img_rgb + 0.3 * mask_rgb).astype(np.uint8)\n",
        "    return Image.fromarray(overlaid)\n",
        "\n",
        "\n",
        "def predict_dcm(file):\n",
        "    dcm = pydicom.dcmread(file.name)\n",
        "    img = dcm.pixel_array.astype(np.float32)\n",
        "    img = (img - np.min(img)) / (np.max(img) - np.min(img))\n",
        "    input_tensor = preprocess(img)\n",
        "    with torch.no_grad():\n",
        "        pred = torch.sigmoid(unet_model(input_tensor)).squeeze().numpy()\n",
        "    result = overlay_prediction(img, pred)\n",
        "    return result\n",
        "\n",
        "\n",
        "def predict_nii(file, slice_index):\n",
        "    nifti = nib.load(file.name)\n",
        "    data = nifti.get_fdata()\n",
        "    slice_img = data[:, :, slice_index]\n",
        "    norm_img = (slice_img - np.min(slice_img)) / (np.max(slice_img) - np.min(slice_img))\n",
        "    input_tensor = preprocess(norm_img)\n",
        "    with torch.no_grad():\n",
        "        pred = torch.sigmoid(unetpp_model(input_tensor)).squeeze().numpy()\n",
        "    result = overlay_prediction(norm_img, pred)\n",
        "    return result\n",
        "\n",
        "\n",
        "def xray_interface():\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"# 🩻 Chest X-ray Segmentation\")\n",
        "        file_input = gr.File(label=\"Upload DICOM (.dcm)\")\n",
        "        output_img = gr.Image(label=\"Overlayed Prediction\")\n",
        "        file_input.change(predict_dcm, inputs=file_input, outputs=output_img)\n",
        "    return demo\n",
        "\n",
        "\n",
        "def mri_interface():\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"# 🧠 Brain MRI Segmentation\")\n",
        "        file_input = gr.File(label=\"Upload NIfTI (.nii.gz)\")\n",
        "        slice_slider = gr.Slider(0, 150, step=1, label=\"Slice Index\", value=60)\n",
        "        output_img = gr.Image(label=\"Overlayed Prediction\")\n",
        "        gr.Button(\"Predict\").click(predict_nii, inputs=[file_input, slice_slider], outputs=output_img)\n",
        "    return demo\n",
        "\n",
        "\n",
        "def main():\n",
        "    with gr.TabbedInterface([xray_interface(), mri_interface()], [\"X-ray\", \"MRI\"]):\n",
        "        pass\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "K7E7q1D_u1aV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6aaFF0AWu1X3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# streamlit run inference_demo.py\n",
        "\n",
        "from PIL import Image\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "\n",
        "# Auto-download model weights from Hugging Face Hub\n",
        "def load_model_weights_local_or_hf(model, filename, repo_id, subfolder=None):\n",
        "    if os.path.exists(filename):\n",
        "        model.load_state_dict(torch.load(filename, map_location=\"cpu\"))\n",
        "    else:\n",
        "        print(f\"🔁 Downloading {filename} from HF Hub...\")\n",
        "        model_path = hf_hub_download(repo_id=repo_id, filename=os.path.basename(filename), subfolder=subfolder)\n",
        "        model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# Load models\n",
        "unet_model = UNet()\n",
        "unet_model = load_model_weights_local_or_hf(\n",
        "    unet_model,\n",
        "    filename=\"results/xray_unet_epoch30.pth\",\n",
        "    repo_id=\"your-hf-username/xray-unet\",\n",
        "    subfolder=\"models\"\n",
        ")\n",
        "\n",
        "unetpp_model = UNetPP()\n",
        "unetpp_model = load_model_weights_local_or_hf(\n",
        "    unetpp_model,\n",
        "    filename=\"results/unetpp_epoch25.pth\",\n",
        "    repo_id=\"your-hf-username/mri-unetpp\",\n",
        "    subfolder=\"models\"\n",
        ")\n",
        "\n",
        "\n",
        "# Utils\n",
        "def preprocess(img):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize((256, 256))\n",
        "    ])\n",
        "    return transform(img).unsqueeze(0)\n",
        "\n",
        "def overlay_prediction(img, mask):\n",
        "    img = (img * 255).astype(np.uint8)\n",
        "    img_rgb = np.stack([img]*3, axis=-1)\n",
        "    mask_bin = (mask > 0.5).astype(np.uint8)\n",
        "    mask_rgb = np.zeros_like(img_rgb)\n",
        "    mask_rgb[:, :, 1] = mask_bin * 255\n",
        "    overlaid = (0.7 * img_rgb + 0.3 * mask_rgb).astype(np.uint8)\n",
        "    return Image.fromarray(overlaid)\n",
        "\n",
        "\n",
        "def predict_dcm(file):\n",
        "    dcm = pydicom.dcmread(file.name)\n",
        "    img = dcm.pixel_array.astype(np.float32)\n",
        "    img = (img - np.min(img)) / (np.max(img) - np.min(img))\n",
        "    input_tensor = preprocess(img)\n",
        "    with torch.no_grad():\n",
        "        pred = torch.sigmoid(unet_model(input_tensor)).squeeze().numpy()\n",
        "    result = overlay_prediction(img, pred)\n",
        "    return result\n",
        "\n",
        "\n",
        "def predict_nii(file, slice_index):\n",
        "    nifti = nib.load(file.name)\n",
        "    data = nifti.get_fdata()\n",
        "    slice_img = data[:, :, slice_index]\n",
        "    norm_img = (slice_img - np.min(slice_img)) / (np.max(slice_img) - np.min(slice_img))\n",
        "    input_tensor = preprocess(norm_img)\n",
        "    with torch.no_grad():\n",
        "        pred = torch.sigmoid(unetpp_model(input_tensor)).squeeze().numpy()\n",
        "    result = overlay_prediction(norm_img, pred)\n",
        "    return result\n",
        "\n",
        "\n",
        "def xray_interface():\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"# 🩻 Chest X-ray Segmentation\")\n",
        "        file_input = gr.File(label=\"Upload DICOM (.dcm)\")\n",
        "        output_img = gr.Image(label=\"Overlayed Prediction\")\n",
        "        file_input.change(predict_dcm, inputs=file_input, outputs=output_img)\n",
        "    return demo\n",
        "\n",
        "\n",
        "def mri_interface():\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"# 🧠 Brain MRI Segmentation\")\n",
        "        file_input = gr.File(label=\"Upload NIfTI (.nii.gz)\")\n",
        "        slice_slider = gr.Slider(0, 150, step=1, label=\"Slice Index\", value=60)\n",
        "        output_img = gr.Image(label=\"Overlayed Prediction\")\n",
        "        gr.Button(\"Predict\").click(predict_nii, inputs=[file_input, slice_slider], outputs=output_img)\n",
        "    return demo\n",
        "\n",
        "\n",
        "def main():\n",
        "    with gr.TabbedInterface([xray_interface(), mri_interface()], [\"X-ray\", \"MRI\"]):\n",
        "        pass\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "5VfzoumSu1Vt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1S6WmNspu1SN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# app.py (Gradio HuggingFace Spaces + HF Model Hub 다운로드 지원)\n",
        "\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "import pydicom\n",
        "import nibabel as nib\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from unet_model import UNet\n",
        "from unetpp_model import UNetPP\n",
        "from PIL import Image\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "\n",
        "# Auto-download model weights from Hugging Face Hub\n",
        "def load_model_weights_local_or_hf(model, filename, repo_id, subfolder=None):\n",
        "    if os.path.exists(filename):\n",
        "        model.load_state_dict(torch.load(filename, map_location=\"cpu\"))\n",
        "    else:\n",
        "        print(f\"🔁 Downloading {filename} from HF Hub...\")\n",
        "        model_path = hf_hub_download(repo_id=repo_id, filename=os.path.basename(filename), subfolder=subfolder)\n",
        "        model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# Load models\n",
        "unet_model = UNet()\n",
        "unet_model = load_model_weights_local_or_hf(\n",
        "    unet_model,\n",
        "    filename=\"results/xray_unet_epoch30.pth\",\n",
        "    repo_id=\"your-hf-username/xray-unet\",\n",
        "    subfolder=\"models\"\n",
        ")\n",
        "\n",
        "unetpp_model = UNetPP()\n",
        "unetpp_model = load_model_weights_local_or_hf(\n",
        "    unetpp_model,\n",
        "    filename=\"results/unetpp_epoch25.pth\",\n",
        "    repo_id=\"your-hf-username/mri-unetpp\",\n",
        "    subfolder=\"models\"\n",
        ")\n",
        "\n",
        "\n",
        "# Utils\n",
        "def preprocess(img):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize((256, 256))\n",
        "    ])\n",
        "    return transform(img).unsqueeze(0)\n",
        "\n",
        "def overlay_prediction(img, mask):\n",
        "    img = (img * 255).astype(np.uint8)\n",
        "    img_rgb = np.stack([img]*3, axis=-1)\n",
        "    mask_bin = (mask > 0.5).astype(np.uint8)\n",
        "    mask_rgb = np.zeros_like(img_rgb)\n",
        "    mask_rgb[:, :, 1] = mask_bin * 255\n",
        "    overlaid = (0.7 * img_rgb + 0.3 * mask_rgb).astype(np.uint8)\n",
        "    return Image.fromarray(overlaid)\n",
        "\n",
        "\n",
        "def predict_dcm(file):\n",
        "    dcm = pydicom.dcmread(file.name)\n",
        "    img = dcm.pixel_array.astype(np.float32)\n",
        "    img = (img - np.min(img)) / (np.max(img) - np.min(img))\n",
        "    input_tensor = preprocess(img)\n",
        "    with torch.no_grad():\n",
        "        pred = torch.sigmoid(unet_model(input_tensor)).squeeze().numpy()\n",
        "    result = overlay_prediction(img, pred)\n",
        "    return result\n",
        "\n",
        "\n",
        "def predict_nii(file, slice_index):\n",
        "    nifti = nib.load(file.name)\n",
        "    data = nifti.get_fdata()\n",
        "    slice_img = data[:, :, slice_index]\n",
        "    norm_img = (slice_img - np.min(slice_img)) / (np.max(slice_img) - np.min(slice_img))\n",
        "    input_tensor = preprocess(norm_img)\n",
        "    with torch.no_grad():\n",
        "        pred = torch.sigmoid(unetpp_model(input_tensor)).squeeze().numpy()\n",
        "    result = overlay_prediction(norm_img, pred)\n",
        "    return result\n",
        "\n",
        "\n",
        "def xray_interface():\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"# 🩻 Chest X-ray Segmentation\")\n",
        "        file_input = gr.File(label=\"Upload DICOM (.dcm)\")\n",
        "        output_img = gr.Image(label=\"Overlayed Prediction\")\n",
        "        file_input.change(predict_dcm, inputs=file_input, outputs=output_img)\n",
        "    return demo\n",
        "\n",
        "\n",
        "def mri_interface():\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"# 🧠 Brain MRI Segmentation\")\n",
        "        file_input = gr.File(label=\"Upload NIfTI (.nii.gz)\")\n",
        "        slice_slider = gr.Slider(0, 150, step=1, label=\"Slice Index\", value=60)\n",
        "        output_img = gr.Image(label=\"Overlayed Prediction\")\n",
        "        gr.Button(\"Predict\").click(predict_nii, inputs=[file_input, slice_slider], outputs=output_img)\n",
        "    return demo\n",
        "\n",
        "\n",
        "def main():\n",
        "    with gr.TabbedInterface([xray_interface(), mri_interface()], [\"X-ray\", \"MRI\"]):\n",
        "        pass\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "0EkjatXRu1Pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SBFYwxy9u1NQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Chest X-ray DICOM 실시간 예측 데모 (Streamlit)\n",
        "\n",
        "# app.py (Gradio HuggingFace Spaces + HF Model Hub 다운로드 지원)\n",
        "## streamlit run dicom_xray_streamlit.py\n",
        "\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "import pydicom\n",
        "import nibabel as nib\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from unet_model import UNet\n",
        "from unetpp_model import UNetPP\n",
        "from PIL import Image\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "\n",
        "# Auto-download model weights from Hugging Face Hub\n",
        "def load_model_weights_local_or_hf(model, filename, repo_id, subfolder=None):\n",
        "    if os.path.exists(filename):\n",
        "        model.load_state_dict(torch.load(filename, map_location=\"cpu\"))\n",
        "    else:\n",
        "        print(f\"🔁 Downloading {filename} from HF Hub...\")\n",
        "        model_path = hf_hub_download(repo_id=repo_id, filename=os.path.basename(filename), subfolder=subfolder)\n",
        "        model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# Load models\n",
        "unet_model = UNet()\n",
        "unet_model = load_model_weights_local_or_hf(\n",
        "    unet_model,\n",
        "    filename=\"results/xray_unet_epoch30.pth\",\n",
        "    repo_id=\"your-hf-username/xray-unet\",\n",
        "    subfolder=\"models\"\n",
        ")\n",
        "\n",
        "unetpp_model = UNetPP()\n",
        "unetpp_model = load_model_weights_local_or_hf(\n",
        "    unetpp_model,\n",
        "    filename=\"results/unetpp_epoch25.pth\",\n",
        "    repo_id=\"your-hf-username/mri-unetpp\",\n",
        "    subfolder=\"models\"\n",
        ")\n",
        "\n",
        "\n",
        "# Utils\n",
        "def preprocess(img):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize((256, 256))\n",
        "    ])\n",
        "    return transform(img).unsqueeze(0)\n",
        "\n",
        "def overlay_prediction(img, mask):\n",
        "    img = (img * 255).astype(np.uint8)\n",
        "    img_rgb = np.stack([img]*3, axis=-1)\n",
        "    mask_bin = (mask > 0.5).astype(np.uint8)\n",
        "    mask_rgb = np.zeros_like(img_rgb)\n",
        "    mask_rgb[:, :, 1] = mask_bin * 255\n",
        "    overlaid = (0.7 * img_rgb + 0.3 * mask_rgb).astype(np.uint8)\n",
        "    return Image.fromarray(overlaid)\n",
        "\n",
        "\n",
        "def predict_dcm(file):\n",
        "    dcm = pydicom.dcmread(file.name)\n",
        "    img = dcm.pixel_array.astype(np.float32)\n",
        "    img = (img - np.min(img)) / (np.max(img) - np.min(img))\n",
        "    input_tensor = preprocess(img)\n",
        "    with torch.no_grad():\n",
        "        pred = torch.sigmoid(unet_model(input_tensor)).squeeze().numpy()\n",
        "    result = overlay_prediction(img, pred)\n",
        "    return result\n",
        "\n",
        "\n",
        "def predict_nii(file, slice_index):\n",
        "    nifti = nib.load(file.name)\n",
        "    data = nifti.get_fdata()\n",
        "    slice_img = data[:, :, slice_index]\n",
        "    norm_img = (slice_img - np.min(slice_img)) / (np.max(slice_img) - np.min(slice_img))\n",
        "    input_tensor = preprocess(norm_img)\n",
        "    with torch.no_grad():\n",
        "        pred = torch.sigmoid(unetpp_model(input_tensor)).squeeze().numpy()\n",
        "    result = overlay_prediction(norm_img, pred)\n",
        "    return result\n",
        "\n",
        "\n",
        "def xray_interface():\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"# 🩻 Chest X-ray Segmentation\")\n",
        "        file_input = gr.File(label=\"Upload DICOM (.dcm)\")\n",
        "        output_img = gr.Image(label=\"Overlayed Prediction\")\n",
        "        file_input.change(predict_dcm, inputs=file_input, outputs=output_img)\n",
        "    return demo\n",
        "\n",
        "\n",
        "def mri_interface():\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"# 🧠 Brain MRI Segmentation\")\n",
        "        file_input = gr.File(label=\"Upload NIfTI (.nii.gz)\")\n",
        "        slice_slider = gr.Slider(0, 150, step=1, label=\"Slice Index\", value=60)\n",
        "        output_img = gr.Image(label=\"Overlayed Prediction\")\n",
        "        gr.Button(\"Predict\").click(predict_nii, inputs=[file_input, slice_slider], outputs=output_img)\n",
        "    return demo\n",
        "\n",
        "\n",
        "def main():\n",
        "    with gr.TabbedInterface([xray_interface(), mri_interface()], [\"X-ray\", \"MRI\"]):\n",
        "        pass\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "cujfq8v3u1KH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "52E64L3Cu1G_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Flask API 서버\n",
        "\n",
        "# app.py (Gradio HuggingFace Spaces + HF Model Hub 다운로드 지원)\n",
        "\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "import pydicom\n",
        "import nibabel as nib\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from unet_model import UNet\n",
        "from unetpp_model import UNetPP\n",
        "from PIL import Image\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "\n",
        "# Auto-download model weights from Hugging Face Hub\n",
        "def load_model_weights_local_or_hf(model, filename, repo_id, subfolder=None):\n",
        "    if os.path.exists(filename):\n",
        "        model.load_state_dict(torch.load(filename, map_location=\"cpu\"))\n",
        "    else:\n",
        "        print(f\"🔁 Downloading {filename} from HF Hub...\")\n",
        "        model_path = hf_hub_download(repo_id=repo_id, filename=os.path.basename(filename), subfolder=subfolder)\n",
        "        model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# Load models\n",
        "unet_model = UNet()\n",
        "unet_model = load_model_weights_local_or_hf(\n",
        "    unet_model,\n",
        "    filename=\"results/xray_unet_epoch30.pth\",\n",
        "    repo_id=\"your-hf-username/xray-unet\",\n",
        "    subfolder=\"models\"\n",
        ")\n",
        "\n",
        "unetpp_model = UNetPP()\n",
        "unetpp_model = load_model_weights_local_or_hf(\n",
        "    unetpp_model,\n",
        "    filename=\"results/unetpp_epoch25.pth\",\n",
        "    repo_id=\"your-hf-username/mri-unetpp\",\n",
        "    subfolder=\"models\"\n",
        ")\n",
        "\n",
        "\n",
        "# Utils\n",
        "def preprocess(img):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize((256, 256))\n",
        "    ])\n",
        "    return transform(img).unsqueeze(0)\n",
        "\n",
        "def overlay_prediction(img, mask):\n",
        "    img = (img * 255).astype(np.uint8)\n",
        "    img_rgb = np.stack([img]*3, axis=-1)\n",
        "    mask_bin = (mask > 0.5).astype(np.uint8)\n",
        "    mask_rgb = np.zeros_like(img_rgb)\n",
        "    mask_rgb[:, :, 1] = mask_bin * 255\n",
        "    overlaid = (0.7 * img_rgb + 0.3 * mask_rgb).astype(np.uint8)\n",
        "    return Image.fromarray(overlaid)\n",
        "\n",
        "\n",
        "def predict_dcm(file):\n",
        "    dcm = pydicom.dcmread(file.name)\n",
        "    img = dcm.pixel_array.astype(np.float32)\n",
        "    img = (img - np.min(img)) / (np.max(img) - np.min(img))\n",
        "    input_tensor = preprocess(img)\n",
        "    with torch.no_grad():\n",
        "        pred = torch.sigmoid(unet_model(input_tensor)).squeeze().numpy()\n",
        "    result = overlay_prediction(img, pred)\n",
        "    return result\n",
        "\n",
        "\n",
        "def predict_nii(file, slice_index):\n",
        "    nifti = nib.load(file.name)\n",
        "    data = nifti.get_fdata()\n",
        "    slice_img = data[:, :, slice_index]\n",
        "    norm_img = (slice_img - np.min(slice_img)) / (np.max(slice_img) - np.min(slice_img))\n",
        "    input_tensor = preprocess(norm_img)\n",
        "    with torch.no_grad():\n",
        "        pred = torch.sigmoid(unetpp_model(input_tensor)).squeeze().numpy()\n",
        "    result = overlay_prediction(norm_img, pred)\n",
        "    return result\n",
        "\n",
        "\n",
        "def xray_interface():\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"# 🩻 Chest X-ray Segmentation\")\n",
        "        file_input = gr.File(label=\"Upload DICOM (.dcm)\")\n",
        "        output_img = gr.Image(label=\"Overlayed Prediction\")\n",
        "        file_input.change(predict_dcm, inputs=file_input, outputs=output_img)\n",
        "    return demo\n",
        "\n",
        "\n",
        "def mri_interface():\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"# 🧠 Brain MRI Segmentation\")\n",
        "        file_input = gr.File(label=\"Upload NIfTI (.nii.gz)\")\n",
        "        slice_slider = gr.Slider(0, 150, step=1, label=\"Slice Index\", value=60)\n",
        "        output_img = gr.Image(label=\"Overlayed Prediction\")\n",
        "        gr.Button(\"Predict\").click(predict_nii, inputs=[file_input, slice_slider], outputs=output_img)\n",
        "    return demo\n",
        "\n",
        "\n",
        "def main():\n",
        "    with gr.TabbedInterface([xray_interface(), mri_interface()], [\"X-ray\", \"MRI\"]):\n",
        "        pass\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "yuasu74tu1CL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iifm3mf7u0-a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}